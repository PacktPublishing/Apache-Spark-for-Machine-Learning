{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7b773ab5-e13c-469c-a626-3e510959c7c5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.databricks.v1+bamboolib_hint": "{\"pd.DataFrames\": [], \"version\": \"0.0.1\"}",
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+------------------+------------------+----------+------------------+--------+---------+-----+\n|MedInc|HouseAge|          AveRooms|         AveBedrms|Population|          AveOccup|Latitude|Longitude|label|\n+------+--------+------------------+------------------+----------+------------------+--------+---------+-----+\n|8.3252|    41.0| 6.984126984126984|1.0238095238095237|     322.0|2.5555555555555554|   37.88|  -122.23|4.526|\n|8.3014|    21.0| 6.238137082601054|0.9718804920913884|    2401.0| 2.109841827768014|   37.86|  -122.22|3.585|\n|7.2574|    52.0| 8.288135593220339| 1.073446327683616|     496.0|2.8022598870056497|   37.85|  -122.24|3.521|\n|5.6431|    52.0|5.8173515981735155|1.0730593607305936|     558.0| 2.547945205479452|   37.85|  -122.25|3.413|\n|3.8462|    52.0| 6.281853281853282|1.0810810810810811|     565.0|2.1814671814671813|   37.85|  -122.25|3.422|\n+------+--------+------------------+------------------+----------+------------------+--------+---------+-----+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import LinearRegression, GeneralizedLinearRegression, DecisionTreeRegressor, RandomForestRegressor, GBTRegressor\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "# Create a SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"RegressionPipelineExample\") \\\n",
    "    .getOrCreate()\n",
    "housing = fetch_california_housing()\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(data=housing.data,columns=housing.feature_names)\n",
    "df['label'] = housing.target\n",
    "df_data = spark.createDataFrame(df)\n",
    "df_data.show(5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "945fe42b-eacc-4a8b-b3bd-55fc5a9712cb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4ed223fb-e71e-4e64-991f-5172f28fcf46",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+------------------+------------------+----------+------------------+--------+---------+-----+-----------------------------------------------------------------------------------------+\n|MedInc|HouseAge|          AveRooms|         AveBedrms|Population|          AveOccup|Latitude|Longitude|label|                                                                                 features|\n+------+--------+------------------+------------------+----------+------------------+--------+---------+-----+-----------------------------------------------------------------------------------------+\n|8.3252|    41.0| 6.984126984126984|1.0238095238095237|     322.0|2.5555555555555554|   37.88|  -122.23|4.526|[8.3252,41.0,6.984126984126984,1.0238095238095237,322.0,2.5555555555555554,37.88,-122.23]|\n|8.3014|    21.0| 6.238137082601054|0.9718804920913884|    2401.0| 2.109841827768014|   37.86|  -122.22|3.585|[8.3014,21.0,6.238137082601054,0.9718804920913884,2401.0,2.109841827768014,37.86,-122.22]|\n|7.2574|    52.0| 8.288135593220339| 1.073446327683616|     496.0|2.8022598870056497|   37.85|  -122.24|3.521| [7.2574,52.0,8.288135593220339,1.073446327683616,496.0,2.8022598870056497,37.85,-122.24]|\n|5.6431|    52.0|5.8173515981735155|1.0730593607305936|     558.0| 2.547945205479452|   37.85|  -122.25|3.413|[5.6431,52.0,5.8173515981735155,1.0730593607305936,558.0,2.547945205479452,37.85,-122.25]|\n|3.8462|    52.0| 6.281853281853282|1.0810810810810811|     565.0|2.1814671814671813|   37.85|  -122.25|3.422|[3.8462,52.0,6.281853281853282,1.0810810810810811,565.0,2.1814671814671813,37.85,-122.25]|\n+------+--------+------------------+------------------+----------+------------------+--------+---------+-----+-----------------------------------------------------------------------------------------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "# Prepare the features column\n",
    "feature_cols = df_data.columns[:-1]  # Assuming the last column is the label\n",
    "assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")\n",
    "df_data = assembler.transform(df_data)\n",
    "df_data.show(5,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "685bb471-2391-49c0-871d-48e426a52511",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Scale and normalize features\n",
    "scaler = StandardScaler(inputCol=\"raw_features\", outputCol=\"scaled_features\", withStd=True, withMean=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5106b59a-b9ab-40d7-abd1-91ca14fb7837",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "(trainingData, testData) = df_data.randomSplit([0.8, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c48d1307-c849-4ad5-9bf2-a19cc33314ff",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression RMSE: 0.7154279207799202\nGeneral Linear Regression RMSE: 0.7154279207799202\nDecision Tree Regression RMSE: 0.7062000747791418\nRandom Forest Regression RMSE: 0.6589518171055013\nGradient Boosted Tree Regression RMSE: 0.5691318056290677\n"
     ]
    }
   ],
   "source": [
    "# Initialize regression models\n",
    "lr = LinearRegression(featuresCol=\"features\", labelCol=\"label\")\n",
    "glr = GeneralizedLinearRegression(featuresCol=\"features\", labelCol=\"label\")\n",
    "dt = DecisionTreeRegressor(featuresCol=\"features\", labelCol=\"label\")\n",
    "rf = RandomForestRegressor(featuresCol=\"features\", labelCol=\"label\")\n",
    "gbt = GBTRegressor(featuresCol=\"features\", labelCol=\"label\")\n",
    "\n",
    "# Define a pipeline for each regression algorithm\n",
    "pipeline_lr = Pipeline(stages=[lr])\n",
    "pipeline_glr = Pipeline(stages=[glr])\n",
    "pipeline_dt = Pipeline(stages=[dt])\n",
    "pipeline_rf = Pipeline(stages=[rf])\n",
    "pipeline_gbt = Pipeline(stages=[gbt])\n",
    "\n",
    "# Fit the pipelines\n",
    "model_lr = pipeline_lr.fit(trainingData)\n",
    "model_glr = pipeline_glr.fit(trainingData)\n",
    "model_dt = pipeline_dt.fit(trainingData)\n",
    "model_rf = pipeline_rf.fit(trainingData)\n",
    "model_gbt = pipeline_gbt.fit(trainingData)\n",
    "\n",
    "# Make predictions\n",
    "predictions_lr = model_lr.transform(testData)\n",
    "predictions_glr = model_glr.transform(testData)\n",
    "predictions_dt = model_dt.transform(testData)\n",
    "predictions_rf = model_rf.transform(testData)\n",
    "predictions_gbt = model_gbt.transform(testData)\n",
    "\n",
    "# Evaluate the models\n",
    "evaluator = RegressionEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "\n",
    "rmse_lr = evaluator.evaluate(predictions_lr)\n",
    "rmse_glr = evaluator.evaluate(predictions_glr)\n",
    "rmse_dt = evaluator.evaluate(predictions_dt)\n",
    "rmse_rf = evaluator.evaluate(predictions_rf)\n",
    "rmse_gbt = evaluator.evaluate(predictions_gbt)\n",
    "\n",
    "print(\"Linear Regression RMSE:\", rmse_lr)\n",
    "print(\"General Linear Regression RMSE:\", rmse_glr)\n",
    "print(\"Decision Tree Regression RMSE:\", rmse_dt)\n",
    "print(\"Random Forest Regression RMSE:\", rmse_rf)\n",
    "print(\"Gradient Boosted Tree Regression RMSE:\", rmse_gbt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a8bbd44f-16fc-4f43-a333-644da044981d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+------------------+------------------+----------+------------------+--------+---------+-----+------------------------------------------------------------+------------------+\n|MedInc|HouseAge|          AveRooms|         AveBedrms|Population|          AveOccup|Latitude|Longitude|label|                                                    features|        prediction|\n+------+--------+------------------+------------------+----------+------------------+--------+---------+-----+------------------------------------------------------------+------------------+\n|0.7403|    37.0| 4.491428571428571|1.1485714285714286|    1046.0|2.9885714285714284|   37.96|  -122.37|0.686|[0.7403,37.0,4.491428571428571,1.1485714285714286,1046.0,...| 1.143277544256371|\n|  0.75|    52.0| 2.823529411764706|0.9117647058823529|     191.0| 5.617647058823529|    37.8|  -122.28|1.625|[0.75,52.0,2.823529411764706,0.9117647058823529,191.0,5.6...| 1.356556401944033|\n|0.8075|    52.0| 2.490322580645161|1.0580645161290323|     346.0| 2.232258064516129|   37.81|  -122.28|1.375|[0.8075,52.0,2.490322580645161,1.0580645161290323,346.0,2...|1.5179285425528377|\n|0.8668|    52.0|2.4431818181818183|0.9886363636363636|     904.0|10.272727272727273|    37.8|  -122.28|1.375|[0.8668,52.0,2.4431818181818183,0.9886363636363636,904.0,...|1.4754497779643216|\n|0.9011|    50.0| 6.229508196721311|1.5573770491803278|     377.0|3.0901639344262297|   37.81|  -122.29|0.861|[0.9011,50.0,6.229508196721311,1.5573770491803278,377.0,3...|1.4355508319745525|\n+------+--------+------------------+------------------+----------+------------------+--------+---------+-----+------------------------------------------------------------+------------------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "predictions_lr.show(5,60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "14b96224-558b-4b56-a9f7-1dc996bb620a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f333945b-61f9-485f-99c5-2def77242449",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "# Define parameter grids for hyperparameter tuning\n",
    "paramGrid_lr = ParamGridBuilder() \\\n",
    "    .addGrid(lr.regParam, [0.1, 0.01]) \\\n",
    "    .addGrid(lr.elasticNetParam, [0.0, 0.5, 1.0]) \\\n",
    "    .build()\n",
    "\n",
    "paramGrid_glr = ParamGridBuilder() \\\n",
    "    .addGrid(glr.regParam, [0.1, 0.01]) \\\n",
    "    .addGrid(glr.maxIter, [10, 20]) \\\n",
    "    .build()\n",
    "\n",
    "paramGrid_dt = ParamGridBuilder() \\\n",
    "    .addGrid(dt.maxDepth, [5, 10, 20]) \\\n",
    "    .addGrid(dt.maxBins, [16, 32, 64]) \\\n",
    "    .build()\n",
    "\n",
    "paramGrid_rf = ParamGridBuilder() \\\n",
    "    .addGrid(rf.numTrees, [50, 100, 200]) \\\n",
    "    .addGrid(rf.maxDepth, [5, 10, 20]) \\\n",
    "    .build()\n",
    "\n",
    "paramGrid_gbt = ParamGridBuilder() \\\n",
    "    .addGrid(gbt.maxDepth, [5, 10, 20]) \\\n",
    "    .addGrid(gbt.maxIter, [10, 20, 30]) \\\n",
    "    .build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "84b8c640-d923-47c9-836f-0dfc8e2ec469",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Define evaluator\n",
    "evaluator = RegressionEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"rmse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b8d0a7d8-116a-4e08-9739-f83e12b1762e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Define CrossValidator for each algorithm\n",
    "cv_lr = CrossValidator(estimator=pipeline_lr,\n",
    "                       estimatorParamMaps=paramGrid_lr,\n",
    "                       evaluator=evaluator,\n",
    "                       numFolds=3)\n",
    "\n",
    "cv_dt = CrossValidator(estimator=pipeline_dt,\n",
    "                       estimatorParamMaps=paramGrid_dt,\n",
    "                       evaluator=evaluator,\n",
    "                       numFolds=3)\n",
    "\n",
    "cv_rf = CrossValidator(estimator=pipeline_rf,\n",
    "                       estimatorParamMaps=paramGrid_rf,\n",
    "                       evaluator=evaluator,\n",
    "                       numFolds=3)\n",
    "\n",
    "cv_gbt = CrossValidator(estimator=pipeline_gbt,\n",
    "                        estimatorParamMaps=paramGrid_gbt,\n",
    "                        evaluator=evaluator,\n",
    "                        numFolds=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "442c4d5f-6d29-4ecc-b8a2-186793ebe2a0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Fit the CrossValidators\n",
    "# cvModel_lr = cv_lr.fit(trainingData)\n",
    "#cvModel_dt = cv_dt.fit(trainingData)\n",
    "cvModel_rf = cv_rf.fit(trainingData)\n",
    "# cvModel_gbt = cv_gbt.fit(trainingData)\n",
    "\n",
    "# Make predictions\n",
    "# predictions_lr = cvModel_lr.transform(testData)\n",
    "#predictions_dt = cvModel_dt.transform(testData)\n",
    "predictions_rf = cvModel_rf.transform(testData)\n",
    "# predictions_gbt = cvModel_gbt.transform(testData)\n",
    "\n",
    "# Evaluate the models\n",
    "#rmse_lr = evaluator.evaluate(predictions_lr)\n",
    "#rmse_dt = evaluator.evaluate(predictions_dt)\n",
    "rmse_rf = evaluator.evaluate(predictions_rf)\n",
    "# rmse_gbt = evaluator.evaluate(predictions_gbt)\n",
    "\n",
    "# Print the RMSE of each model\n",
    "#print(\"Linear Regression RMSE:\", rmse_lr)\n",
    "#print(\"Decision Tree Regression RMSE:\", rmse_dt)\n",
    "print(\"Random Forest Regression RMSE:\", rmse_rf)\n",
    "# print(\"Gradient Boosted Tree Regression RMSE:\", rmse_gbt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e0d4bacb-f6fc-4025-8066-6150ab8bcab7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression RMSE: 0.7180876814041877\n"
     ]
    }
   ],
   "source": [
    "# Print the RMSE of each model\n",
    "#print(\"Linear Regression RMSE:\", rmse_lr)\n",
    "# print(\"Decision Tree Regression RMSE:\", rmse_dt)\n",
    "print(\"Random Forest Regression RMSE:\", rmse_rf)\n",
    "# print(\"Gradient Boosted Tree Regression RMSE:\", rmse_gbt)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "California Housing Dataset",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
